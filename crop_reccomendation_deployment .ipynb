{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bc3a911-cd78-4161-bda0-b00b092afd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Crops: ['muskmelon' 'watermelon' 'papaya' 'papaya' 'apple' 'mango' 'apple'\n",
      " 'mothbeans' 'mungbean' 'lentil']\n",
      "Random Forest Model Accuracy Score: 0.9879\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load Data\n",
    "data = pd.read_csv('Crop_recommendation.csv')\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "data['label'] = le.fit_transform(data['label'])  \n",
    "\n",
    "X = data.drop('label', axis=1)\n",
    "y = data['label']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardize Input Features\n",
    "    ('model', RandomForestClassifier(n_estimators=100, max_depth=6))\n",
    "])\n",
    "\n",
    "# Train Pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Convert Predictions Back to Crop Names\n",
    "y_pred_labels = le.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Predicted Crops:\", y_pred_labels[:10])\n",
    "print(f'Random Forest Model Accuracy Score: {accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c807104-f708-4f75-9ec2-045c2fa699c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.98701299 0.99350649 0.99025974 0.99025974 0.97727273]\n",
      "Mean CV Accuracy: 0.9876623376623377\n",
      "Standard Deviation CV Accuracy: 0.005585925498079636\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold cross-validation\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n",
    "print(\"Standard Deviation CV Accuracy:\", cv_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f9e98a3-d1c3-4178-bcaa-8203cc257e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified CV Scores: [0.99675325 0.98051948 0.99025974 0.98376623 0.98701299]\n",
      "Mean Stratified CV Accuracy: 0.9876623376623377\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=skf, scoring='accuracy')\n",
    "\n",
    "print(\"Stratified CV Scores:\", cv_scores)\n",
    "print(\"Mean Stratified CV Accuracy:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3872ce-d64d-4eb5-a89b-4866917d7a2d",
   "metadata": {},
   "source": [
    "## hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae4fd14e-d1b3-46d6-a9ef-56adfc35cdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'model__max_depth': 7, 'model__n_estimators': 100}\n",
      "Best Accuracy: 0.9863636363636363\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'model__n_estimators': [50, 100, 200],\n",
    "    'model__max_depth': [5, 6, 7],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=skf, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "y_pred_best = best_pipeline.predict(X_test)\n",
    "print(\"Best Accuracy:\", accuracy_score(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df804357-622c-4e25-b161-686faf8a3ba8",
   "metadata": {},
   "source": [
    "## sample data prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afbc4b60-5443-49c3-8a2e-0f17a425d90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Crop: kidneybeans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swara\\anaconda3\\envs\\vertex-env\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sample_data_raw = np.array([[3, 76, 8, 20.8248451, 17.85057083, 94.599279991, 79.20509212]])\n",
    "\n",
    "\n",
    "# Load the Standalone Model\n",
    "# with open(\"model_artifacts/final_model.pkl\", \"rb\") as model_file:\n",
    "#     pipeline, le = pickle.load(model_file)\n",
    "\n",
    "# Example Input Data (N, P, K, Temperature, Humidity, pH, Rainfall)\n",
    "sample_data = np.array([[50, 30, 40, 25.4, 80.2, 6.5, 200.1]])\n",
    "\n",
    "# Predict Crop Recommendation\n",
    "predicted_label = best_pipeline.predict(sample_data_raw)\n",
    "crop_name = le.inverse_transform(predicted_label)[0]\n",
    "\n",
    "print(f\"Recommended Crop: {crop_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31728130-7ff0-4d54-b4c4-2c29251df7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc4d543e-3767-4b0f-9862-906c1d7a47e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model (with Preprocessing) Saved Successfully as 'final_model.joblib'!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump((best_pipeline), \"model_artifacts/model.joblib\")\n",
    "joblib.dump((le),\"model_artifacts/le.joblib\")\n",
    "print(\"Final Model (with Preprocessing) Saved Successfully as 'final_model.joblib'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f65f8d21-5407-46c5-9ecd-32263539d058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kidneybeans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swara\\anaconda3\\envs\\vertex-env\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "sample_data = np.array([[3, 76, 8, 20.8248451, 17.85057083, 94.599279991, 79.20509212]])\n",
    "# with open (\"model_artifacts/final_model.joblib\",\"rb\") as model_file:\n",
    "#     model , le =  joblib.load(model_file)\n",
    "# prediction  = model.predict(sample_data)\n",
    "model = joblib.load(\"model_artifacts/model.joblib\")\n",
    "le = joblib.load(\"model_artifacts/le.joblib\")\n",
    "prediction = model.predict(sample_data)\n",
    "\n",
    "# predicted_crop  =  le.inverse_transform(prediction)\n",
    "prediction  = np.array([9])\n",
    "predicted_crop  =  le.inverse_transform(prediction)\n",
    "print(predicted_crop[0])       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7104901b-7406-4780-8948-6bc51d61c3a4",
   "metadata": {},
   "source": [
    "## further testing of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15760cc9-99a6-46d6-907e-66157ad048e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "print(joblib.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "344b1907-8493-4b6f-8bbb-4ebbcb69b948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swara\\anaconda3\\envs\\vertex-env\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'inverse_transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m sample_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m133\u001b[39m,\u001b[38;5;241m47\u001b[39m,\u001b[38;5;241m24\u001b[39m,\u001b[38;5;241m24\u001b[39m,\u001b[38;5;241m80\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m90\u001b[39m]])\n\u001b[0;32m      8\u001b[0m predicted \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(sample_data)\n\u001b[1;32m----> 9\u001b[0m crop_name \u001b[38;5;241m=\u001b[39m \u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m(predicted)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(crop_name[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'inverse_transform'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "with open(\"model_artifacts/model.joblib\", \"rb\") as model_file:\n",
    "    pipeline= joblib.load(model_file)\n",
    "\n",
    "# Example Input Data (N, P, K, Temperature, Humidity, pH, Rainfall)\n",
    "sample_data = np.array([[133,47,24,24,80,7,90]])\n",
    "predicted = pipeline.predict(sample_data)\n",
    "crop_name = le.inverse_transform(predicted)\n",
    "print(crop_name[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869754db-ce98-45da-871d-ad5e560d3b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Your sample data as a NumPy array\n",
    "sample_data_raw = np.array([[3, 76, 8, 20.8248451, 17.85057083, 94.599279991, 79.20509212]])\n",
    "\n",
    "# Convert NumPy array to a Python list\n",
    "sample_data_list = sample_data_raw.tolist()\n",
    "\n",
    "# Create the JSON request format\n",
    "payload = {\n",
    "    \"instances\": sample_data_list\n",
    "}\n",
    "\n",
    "# Save to a JSON file (optional)\n",
    "with open(\"prediction_input.json\", \"w\") as f:\n",
    "    json.dump(payload, f, indent=4)\n",
    "\n",
    "print(\"Formatted JSON:\", json.dumps(payload, indent=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vertex-env]",
   "language": "python",
   "name": "conda-env-vertex-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
